{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collision Percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code was used to compute the collision percentages cited in the article \"Behavioral Diversity Generation in Autonomous Exploration Through Reuse of Past Experience\" by Fabien C. Y. Benureau and Pierre-Yves Oudeyer.\n",
    "\n",
    "It available [there](http://fabien.benureau.com/code/frontiers2016.html) and is distributed under the [Open Science License](http://fabien.benureau.com/openscience.html). For any questions and remarks about the code, contact [fabien.benureau@gmail.com](mailto:fabien.benureau@gmail.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import experiments\n",
    "\n",
    "import dotdot\n",
    "from fig13_cluster import rmb_reuse_short\n",
    "from fig14_cluster import dissimilar\n",
    "from fig15_cluster import pool\n",
    "\n",
    "\n",
    "def collisions(expcfg):\n",
    "    try:\n",
    "        # only consider random motor babbling\n",
    "        rmb_steps = expcfg.exploration.explorer.eras[0]\n",
    "    except KeyError:\n",
    "        rmb_steps = expcfg.exploration.steps\n",
    "    \n",
    "    cols, total = 0, 0\n",
    "    for i in range(expcfg.exp.repetitions):  \n",
    "        data = experiments.load_exploration(expcfg, rep=i)\n",
    "        for s in data['s_signals'][:rmb_steps]:\n",
    "            total += 1\n",
    "            if s['push_saliency'] > 0:\n",
    "                cols += 1\n",
    "    \n",
    "    return cols, total\n",
    "\n",
    "\n",
    "# getting expcfg of relevant source tasks\n",
    "expcfgs = rmb_reuse_short()\n",
    "cube_src_cfg = expcfgs[0][1]\n",
    "ball_src_cfg = expcfgs[1][1]\n",
    "\n",
    "expcfgs = dissimilar()\n",
    "displaced_src_cfg = expcfgs[1][1]\n",
    "\n",
    "expcfgs = pool()\n",
    "pool_nor_cfg = expcfgs[0][0]\n",
    "\n",
    "# computing collisions\n",
    "cube_cols      = collisions(cube_src_cfg)\n",
    "ball_cols      = collisions(ball_src_cfg)\n",
    "displaced_cols = collisions(displaced_src_cfg)\n",
    "pool_cols      = collisions(pool_nor_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_collisions(name, col_data):\n",
    "    return '{}: {: 5d}/{} collisions, {:.3f}% probability'.format(\n",
    "        name, col_data[0], col_data[1], 100.0*col_data[0]/col_data[1])\n",
    "\n",
    "print(print_collisions('cube     ', cube_cols))\n",
    "print(print_collisions('ball     ', ball_cols))\n",
    "print(print_collisions('displaced', displaced_cols))\n",
    "print(print_collisions('pool     ', pool_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# some precomputations\n",
    "logs = [None] + [math.log(k) for k in range(1, 10000)]\n",
    "logfacts = [0.0]\n",
    "for k in range(1, 10000):\n",
    "    logfacts.append(logfacts[-1] + logs[k])\n",
    "logfacts[0] = 1.0\n",
    "\n",
    "def nCr(n,r): \n",
    "    \"\"\"Compute n choose r\"\"\"\n",
    "    return math.exp(logfacts[n] - logfacts[r] - logfacts[n-r])\n",
    "\n",
    "def proba_collision(col_data, steps, n):\n",
    "    \"\"\"Return the probability to observe at least n collision over a given number of steps\"\"\"\n",
    "    p_col = 1.0*col_data[0]/col_data[1]\n",
    "    p = 0\n",
    "    for k in range(n, steps+1):\n",
    "        p += nCr(steps, k) * p_col**k * (1-p_col)**(steps - k)\n",
    "    return p\n",
    "\n",
    "def print_proba_collision(name, col_data, steps, n=1):\n",
    "    print('{}: there is{: 6.2f}% to observe at least {} collisions over {} steps'.format(\n",
    "        name, 100.0*proba_collision(col_data, steps, n=n), n, steps))\n",
    "    \n",
    "print_proba_collision('cube     ', cube_cols,      200, n=1)\n",
    "print_proba_collision('ball     ', ball_cols,      200, n=1)\n",
    "print_proba_collision('ball     ', ball_cols,      100, n=1)\n",
    "print_proba_collision('displaced', displaced_cols, 200, n=1)\n",
    "print_proba_collision('displaced', displaced_cols, 100, n=1)\n",
    "print_proba_collision('pool     ', pool_cols,      300, n=1)\n",
    "print('')\n",
    "print_proba_collision('cube     ', cube_cols,      200, n=2)\n",
    "print_proba_collision('ball     ', ball_cols,      200, n=2)\n",
    "print_proba_collision('displaced', displaced_cols, 200, n=2)\n",
    "print_proba_collision('pool     ', pool_cols,      300, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provenance Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cluster provenance code examines all the exploration data files of this experiment to check and compare their embedded provenance data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import provenance # this may take a minute or two.\n",
    "prov_data = provenance.cluster([[cube_src_cfg, ball_src_cfg, displaced_src_cfg, pool_nor_cfg]]) \n",
    "print(prov_data.message())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}